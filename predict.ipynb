{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2swxng3yMEx"
   },
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ifo1jRwByQtB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pickle import load\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tS7SE1ujyTVC"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kUl6StnyVlJ"
   },
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "\n",
    "# load the model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Parameters configuration\n",
    "MAX_SEQUENCE_LENGTH = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2ci7l0L709h"
   },
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "L9sSWsmf74Vf",
    "outputId": "43624f6a-d9ff-48d9-b3e1-2df8bbbef65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def text_prepocessing(text):\n",
    "  # noise removal  \n",
    "  text = re.sub(r'[xX]', '', text) # remove 'x'\n",
    "  \n",
    "  # normalization\n",
    "  text = text.lower() # convert to lowercase text\n",
    "  text = re.sub(r'\\-',' ', text) # seperate words like 'video-related'\n",
    "  text = re.sub(r'[-+]?\\d*\\.?\\d+', ' NUMBER ', text) # replace numbers with \"NUMBER\"\n",
    "  text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # remove punctuation  \n",
    "  \n",
    "  text = ' '.join(word for word in text.split() if word not in stop_words) # remove stop words\n",
    "  text = ' '.join(lemmatize_verbs(text.split())) # Lemmatization\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzFMKM17zQPX"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OEOJht2BzEga",
    "outputId": "3d664ebc-a2eb-4298-f690-ef1ed1bb6495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product that the complaint is about:  Mortgage\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "new_complaint = [\"I have an open and current mortgage with Chase Bank # XXXX. Chase is reporting the loan payments to XXXX but XXXX is surpressing the information and reporting the loan as Discharged in BK. This mortgage was reaffirmed in a Chapter XXXX BK discharged dated XXXX/XXXX/2013. Chase keeps referring to BK Law for Chapter XXXX and we keep providing documentation for Chapter XXXX, and the account should be open and current with all the payments. \"]\n",
    "# text preprocessing\n",
    "processed = [text_prepocessing(new_complaint[0])]\n",
    "# tokenization and padding\n",
    "seq = tokenizer.texts_to_sequences(processed)\n",
    "seq_padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# prediction\n",
    "y_predict = model.predict(seq_padded)\n",
    "labels = ['Bank account or service', \n",
    "          'Consumer Loan', \n",
    "          'Credit card', \n",
    "          'Credit reporting', \n",
    "          'Debt collection', \n",
    "          'Money transfers', \n",
    "          'Mortgage',\n",
    "          'Other financial service',\n",
    "          'Payday loan',\n",
    "          'Prepaid card',\n",
    "          'Student loan']\n",
    "print(\"The product that the complaint is about: \", labels[np.argmax(y_predict)])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "predict.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
